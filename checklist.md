## Validation Checklist for the Cloud-Native Map
#### The checklist is structured around the 16 high-level practice groups identified in the map. Each high-level practice group served as a primary checklist item, under which specific questions were formulated to evaluate the content, sub-practices, tools, and their alignment with the identified quality attributes (QAs)


| **Checklist Items**         | **Validation Questions**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
|---------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Container Construction**            | 1. **Definition Accuracy:** Does the practice accurately define container construction principles, such as Multi-Stage Image Build and Distroless Images?<br>2. **Sub-Practices Inclusion:** Are all relevant sub-practices (e.g., Multi-Stage Image Build, Distroless Images, Image Versioning and Tagging) comprehensively included?<br>3. **Tool Relevance:** Are the associated tools (e.g., Docker, Buildkit, Kaniko, Alpine Linux, Google Distroless Images, Harbor, Artifactory) current and widely adopted?<br>4. **QA Alignment Accuracy:** Is the alignment between container construction sub-practices and QAs like Maintainability (MA), Performance Efficiency (PE), and Reliability (RE) correct?<br>5. **Completeness Check:** Are there any additional sub-practices or tools that should be incorporated to enhance the completeness of the Container Construction practice group? |
| **Container Image Management**        | 1. **Definition Accuracy:** Does the practice accurately define container image management concepts, including Container Registry, Container Access Control, and Container Image Scanning?<br>2. **Sub-Practices Inclusion:** Are all relevant sub-practices (e.g., Container Registry, Container Access Control, Container Image Scanning) comprehensively included?<br>3. **Tool Relevance:** Are the associated tools (e.g., Harbor, Amazon ECR, Azure Registry, Trivy, Aqua Security, Clair) current and widely adopted?<br>4. **QA Alignment Accuracy:** Is the alignment between container image management sub-practices and QAs like Maintainability (MA), Reliability (RE), and Security (SE) correct?<br>5. **Completeness Check:** Are there any additional sub-practices or tools that should be incorporated to enhance the completeness of the Container Image Management practice group? |
| **Container Orchestration**           | 1. **Definition Accuracy:** Does the practice comprehensively cover container orchestration concepts, including Horizontal/Vertical Autoscaling, Storage Orchestration, Load Balancing, Dynamic Resource Allocation, Replication Planning, Package Management, Self-Healing, Rollbacks, Rollouts, Configuration Management, and Health Checks?<br>2. **Sub-Practices Inclusion:** Are all relevant sub-practices adequately represented?<br>3. **Tool Relevance:** Are the associated tools (e.g., Kubernetes HPA/VPA, KEDA, Kubernetes Persistent Volumes, Rook, Kubernetes Services, MetalLB, Kubernetes Scheduler, Kubernetes StatefulSets and ReplicaSets, Helm, Argo Rollouts, Kubernetes ConfigMaps, etcd, Consul, Kubernetes Liveness Probes and Readiness Probes) current and widely adopted?<br>4. **QA Alignment Accuracy:** Is the alignment between container orchestration sub-practices and QAs like Scalability (SC), Performance Efficiency (PE), Reliability (RE), and Resilience (RS) correct?<br>5. **Completeness Check:** Are there any additional sub-practices or tools that should be incorporated to enhance the completeness of the Container Orchestration practice group? |
| **Service Mesh**                      | 1. **Definition Accuracy:** Does the practice accurately define service mesh concepts, including Layer 7 Load Balancing, Retries & Timeouts, Circuit Breaking, Fault Injection, Log, Trace, Metrics Integration, Mutual TLS (mTLS), Service Authorization Policies, and Traffic Shadowing/Mirroring?<br>2. **Sub-Practices Inclusion:** Are all relevant sub-practices comprehensively included?<br>3. **Tool Relevance:** Are the associated tools (e.g., Istio, Linkerd, Consul, Envoy, Hystrix, Resilience4j, Chaos Mesh, Prometheus, Jaeger, Zipkin, Fluentd, OpenTelemetry) current and widely adopted?<br>4. **QA Alignment Accuracy:** Is the alignment between service mesh sub-practices and QAs like Scalability (SC), Reliability (RE), Performance Efficiency (PE), Security (SE), Resilience (RS), and Observability (OB) correct?<br>5. **Completeness Check:** Are there any additional sub-practices or tools that should be incorporated to enhance the completeness of the Service Mesh practice group? |
| **API Gateway**                       | 1. **Definition Accuracy:** Does the practice accurately define API Gateway functionalities, including Dynamic Request Routing, Request Validation, Authentication/Authorization, Rate Limiting, Role-Based Access Control, and API Transformation?<br>2. **Sub-Practices Inclusion:** Are all relevant sub-practices comprehensively included?<br>3. **Tool Relevance:** Are the associated tools (e.g., Kong, NGINX, Ambassador, AWS API Gateway, Tyk, Apigee, MuleSoft) current and widely adopted?<br>4. **QA Alignment Accuracy:** Is the alignment between API Gateway sub-practices and QAs like Scalability (SC), Reliability (RE), Security (SE), Maintainability (MA), and Portability (PO) correct?<br>5. **Completeness Check:** Are there any additional sub-practices or tools that should be incorporated to enhance the completeness of the API Gateway practice group? |
| **Infrastructure as Code (IaC)**      | 1. **Definition Accuracy:** Does the practice comprehensively describe IaC principles and benefits, such as Automated Provisioning, Deployment Modularization, IaC Security Scanning, Infrastructure Code Testing, and Idempotent Deployments?<br>2. **Sub-Practices Inclusion:** Are all relevant sub-practices comprehensively included?<br>3. **Tool Relevance:** Are the associated tools (e.g., Terraform, Ansible, CloudFormation, Pulumi, Checkov, tfsec, Snyk IaC, Terratest, InSpec) current and widely adopted?<br>4. **QA Alignment Accuracy:** Is the alignment between IaC sub-practices and QAs like Maintainability (MA), Portability (PO), Reliability (RE), and Security (SE) correct?<br>5. **Completeness Check:** Are there any additional sub-practices or tools that should be incorporated to enhance the completeness of the Infrastructure as Code (IaC) practice group? |
| **Continuous Integration and Delivery (CI/CD)** | 1. **Pipeline Components:** Does the practice accurately describe CI/CD pipeline components and workflows, including Automated Testing, Pipeline as Code, Vulnerability Scanning, and Continuous Deployment?<br>2. **Sub-Practices Inclusion:** Are all essential sub-practices comprehensively included?<br>3. **Tool Relevance:** Are the associated tools (e.g., Jenkins, GitLab, CircleCI, GitHub Actions, Argo CD, Flux) current and widely adopted?<br>4. **QA Alignment Accuracy:** Is the alignment between CI/CD sub-practices and QAs like Maintainability (MA), Reliability (RE), and Performance Efficiency (PE) correct?<br>5. **Completeness Check:** Are there any additional sub-practices or tools (e.g., container-based deployments, blue-green deployments) that should be incorporated to enhance the completeness of the CI/CD practice group? |
| **Application Monitoring**            | 1. **Definition Accuracy:** Does the practice accurately define application monitoring concepts, including Log Aggregation, Distributed Tracing, Metrics Collection, Comprehensive Instrumentation, Centralized Data Storage, Visualization & Dashboarding, Alerting and Notifications, and Anomaly Detection?<br>2. **Sub-Practices Inclusion:** Are all relevant sub-practices comprehensively included?<br>3. **Tool Relevance:** Are the associated tools (e.g., ELK Stack, Fluentd, Graylog, Jaeger, Zipkin, OpenTelemetry, Prometheus, Grafana, Datadog, InfluxDB, TimescaleDB, New Relic, Splunk ITSI, Elastic APM) current and widely adopted?<br>4. **QA Alignment Accuracy:** Is the alignment between application monitoring sub-practices and QAs like Observability (OB), Performance Efficiency (PE), and Reliability (RE) correct?<br>5. **Completeness Check:** Are there any additional sub-practices or tools that should be incorporated to enhance the completeness of the Application Monitoring practice group? |
| **Service Discovery**                 | 1. **Definition Accuracy:** Does the practice accurately define service discovery concepts, including Dynamic Service Registration, Server-Side Discovery, and Client-Side Discovery?<br>2. **Sub-Practices Inclusion:** Are all relevant sub-practices comprehensively included?<br>3. **Tool Relevance:** Are the associated tools (e.g., Consul, Eureka, Zookeeper, Ribbon, Feign) current and widely adopted?<br>4. **QA Alignment Accuracy:** Is the alignment between service discovery sub-practices and QAs like Scalability (SC), Performance Efficiency (PE), and Reliability (RE) correct?<br>5. **Completeness Check:** Are there any additional sub-practices or tools that should be incorporated to enhance the completeness of the Service Discovery practice group? |
| **Chaos Engineering**                 | 1. **Definition Accuracy:** Does the practice accurately define chaos engineering concepts, including Failure Injection, Fault Tolerance Testing, System Recovery Validation, and Chaos Experiment Automation?<br>2. **Sub-Practices Inclusion:** Are all relevant sub-practices comprehensively included?<br>3. **Tool Relevance:** Are the associated tools (e.g., Chaos Monkey, Chaos Mesh, Gremlin, Chaos Toolkit, LitmusChaos, PowerfulSeal) current and widely adopted?<br>4. **QA Alignment Accuracy:** Is the alignment between chaos engineering sub-practices and QAs like Resilience (RS) and Reliability (RE) correct?<br>5. **Completeness Check:** Are there any additional sub-practices or tools that should be incorporated to enhance the completeness of the Chaos Engineering practice group? |
| **Streaming and Messaging**           | 1. **Definition Accuracy:** Does the practice accurately define streaming and messaging concepts, including Message Brokers, Publish/Subscribe Pattern, Event Streaming, Dead Letter Queues, and Message Replay?<br>2. **Sub-Practices Inclusion:** Are all relevant sub-practices comprehensively included?<br>3. **Tool Relevance:** Are the associated tools (e.g., Apache Kafka, RabbitMQ, Apache ActiveMQ, Redis Pub/Sub, AWS Kinesis, Azure Event Hubs, Amazon SQS DLQ, Event Store) current and widely adopted?<br>4. **QA Alignment Accuracy:** Is the alignment between streaming and messaging sub-practices and QAs like Scalability (SC), Performance Efficiency (PE), and Reliability (RE) correct?<br>5. **Completeness Check:** Are there any additional sub-practices or tools that should be incorporated to enhance the completeness of the Streaming and Messaging practice group? |
| **Serverless**                        | 1. **Definition Accuracy:** Does the practice accurately define serverless concepts, including Function-as-a-Service (FaaS) and Container-as-a-Service (CaaS)?<br>2. **Sub-Practices Inclusion:** Are all relevant sub-practices comprehensively included?<br>3. **Tool Relevance:** Are the associated tools (e.g., AWS Lambda, Azure Functions, AWS Fargate, Azure Container Instances) current and widely adopted?<br>4. **QA Alignment Accuracy:** Is the alignment between serverless sub-practices and QAs like Scalability (SC), Performance Efficiency (PE), Resilience (RS), and Portability (PO) correct?<br>5. **Completeness Check:** Are there any additional sub-practices or tools that should be incorporated to enhance the completeness of the Serverless practice group? |
| **Microservices Architecture**        | 1. **Definition Accuracy:** Does the practice accurately define microservices architecture principles, including Service Decomposition, Bounded Contexts, API Design and Versioning, and Inter-Service Communication?<br>2. **Sub-Practices Inclusion:** Are all relevant sub-practices comprehensively included?<br>3. **Tool Relevance:** Are the associated tools (e.g., OpenAPI, gRPC, REST APIs, Message Queues) current and widely adopted?<br>4. **QA Alignment Accuracy:** Is the alignment between microservices architecture sub-practices and QAs like Scalability (SC), Performance Efficiency (PE), Security (SE), Maintainability (MA), and Reliability (RE) correct?<br>5. **Completeness Check:** Are there any additional sub-practices or tools that should be incorporated to enhance the completeness of the Microservices Architecture practice group? |
| **Data Management and Persistence**   | 1. **Definition Accuracy:** Does the practice accurately define data management and persistence concepts, including Database-as-a-Service (DBaaS), Data Replication and Sharding, Cache Management, and Data Backup and Recovery?<br>2. **Sub-Practices Inclusion:** Are all relevant sub-practices comprehensively included?<br>3. **Tool Relevance:** Are the associated tools (e.g., Amazon RDS, Azure SQL Database, Apache Cassandra, CockroachDB, Redis, Memcached, AWS Backup, Velero, Azure Backup) current and widely adopted?<br>4. **QA Alignment Accuracy:** Is the alignment between data management and persistence sub-practices and QAs like Scalability (SC), Performance Efficiency (PE), Reliability (RE), and Resilience (RS) correct?<br>5. **Completeness Check:** Are there any additional sub-practices or tools that should be incorporated to enhance the completeness of the Data Management and Persistence practice group? |
| **Compliance and Governance**         | 1. **Definition Accuracy:** Does the practice accurately define compliance and governance concepts, including Compliance Auditing, Governance Frameworks, and Policy as Code?<br>2. **Sub-Practices Inclusion:** Are all relevant sub-practices comprehensively included?<br>3. **Tool Relevance:** Are the associated tools (e.g., AWS Config, Azure Policy, Open Policy Agent (OPA), Terraform Sentinel, Conftest) current and widely adopted?<br>4. **QA Alignment Accuracy:** Is the alignment between compliance and governance sub-practices and QAs like Reliability (RE), Resilience (RS), and Security (SE) correct?<br>5. **Completeness Check:** Are there any additional sub-practices or tools that should be incorporated to enhance the completeness of the Compliance and Governance practice group? |
